{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":61542,"databundleVersionId":7516023,"sourceType":"competition"},{"sourceId":6977472,"sourceType":"datasetVersion","datasetId":4005256},{"sourceId":157012862,"sourceType":"kernelVersion"}],"dockerImageVersionId":30627,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -r ~/.cache/huggingface\n!unzip -o /kaggle/input/save-models/modules.zip  -d /\n!tree ~/.cache/huggingface -lh","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-12-24T08:25:29.552596Z","iopub.execute_input":"2024-12-24T08:25:29.552956Z","iopub.status.idle":"2024-12-24T08:25:32.683197Z","shell.execute_reply.started":"2024-12-24T08:25:29.552924Z","shell.execute_reply":"2024-12-24T08:25:32.682056Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%reset -f\nimport os\npath_input = '/kaggle/input/'\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom scipy.special import logsumexp\n!pip install /kaggle/input/save-models/einops-0.7.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2024-12-24T08:25:32.685240Z","iopub.execute_input":"2024-12-24T08:25:32.685535Z","iopub.status.idle":"2024-12-24T08:26:13.381695Z","shell.execute_reply.started":"2024-12-24T08:25:32.685510Z","shell.execute_reply":"2024-12-24T08:26:13.380708Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tab_train = pd.read_csv(f'{path_input}/llm-detect-ai-generated-text/train_essays.csv')\ntab_train['set'] = 'train'\ntab_train = tab_train.iloc[:12]\n# tab_daigt = pd.read_csv(f'{path_input}/daigt-v2-train-dataset/train_v2_drcat_02.csv')\n# tab_daigt = tab_daigt[:5000]\n# tab_daigt.rename(columns = {\"label\":\"generated\"}, inplace=True)\n# tab_daigt['set'] = 'daigt'\n# tab_train = pd.concat([tab_train[['text', 'generated', 'set']],\n#                       tab_daigt[['text', 'generated', 'set']]]).reset_index(drop=True)\ntab_train['generated'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-12-24T08:26:13.383331Z","iopub.execute_input":"2024-12-24T08:26:13.383622Z","iopub.status.idle":"2024-12-24T08:26:13.440782Z","shell.execute_reply.started":"2024-12-24T08:26:13.383596Z","shell.execute_reply":"2024-12-24T08:26:13.440105Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tab_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:26:45.678209Z","iopub.execute_input":"2024-12-24T08:26:45.678541Z","iopub.status.idle":"2024-12-24T08:26:45.696118Z","shell.execute_reply.started":"2024-12-24T08:26:45.678516Z","shell.execute_reply":"2024-12-24T08:26:45.694920Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport tqdm\ndevice = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ndtype = torch.float16 if torch.cuda.is_available() else torch.float32\nprint(device, dtype, flush=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-24T08:26:13.478914Z","iopub.status.idle":"2024-12-24T08:26:13.479191Z","shell.execute_reply.started":"2024-12-24T08:26:13.479053Z","shell.execute_reply":"2024-12-24T08:26:13.479066Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import CodeGenTokenizer, GPT2LMHeadModel, OPTForCausalLM, BertLMHeadModel, AutoModelForCausalLM\nprint(device, dtype, flush=True)\n\ndict_llm = {\n   #'gpt2' : ('/kaggle/input/save-models/models/gpt2-xl', GPT2LMHeadModel, 1024, dict()),\n   #'opt'  : (\"/kaggle/input/save-models/models/facebook/opt-2.7b\", OPTForCausalLM, 2048, dict()),\n   # 'bert' : (\"/kaggle/input/save-models/models/bert-base-uncased\", BertLMHeadModel, 2048, {'is_decoder':True}),\n   'phi2' : (\"/kaggle/input/save-models/models/microsoft/phi-2\", AutoModelForCausalLM, 2048,  {'flash_attn':True, 'flash_rotary':True, 'fused_dense':True, 'trust_remote_code':True}),\n}\n\nllm_tokenizer = dict()\nllm_model = dict()\nfor _ in dict_llm:\n    llm_tokenizer[_] = CodeGenTokenizer.from_pretrained(dict_llm[_][0], add_bos_token = True)\n    if llm_tokenizer[_].pad_token is None:\n        llm_tokenizer[_].pad_token = llm_tokenizer[_].eos_token\n    llm_model[_] = dict_llm[_][1].from_pretrained(dict_llm[_][0], torch_dtype=dtype, device_map=device, **dict_llm[_][3])\n    print(_, flush=True)\n\nprint('done', flush=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-24T08:26:13.480616Z","iopub.status.idle":"2024-12-24T08:26:13.480925Z","shell.execute_reply.started":"2024-12-24T08:26:13.480754Z","shell.execute_reply":"2024-12-24T08:26:13.480767Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_entropy(input_ids, logits, attention_mask, token_type_ids=None):\n    with torch.no_grad():\n        logits = torch.log_softmax(logits.float(), dim=-1)\n        # scores S, W ,P\n        tokens = input_ids[:, 1:]\n        attention_mask = attention_mask[:, 1:]\n        \n        entD = torch.sum(logits * torch.exp(logits), dim=-1)[:, 1:]\n        entL = torch.gather(logits[:, :-1, :], dim=-1, index = tokens[:,:,None])[:,:,0]\n        \n        entD = -torch.where(attention_mask!=0, entD, np.nan)\n        entL = -torch.where(attention_mask!=0, entL, np.nan)\n        \n    return entD, entL\n\n\ndef generate_logprob(llm_model, llm_tokenizer, prompt, max_length=None, add_special_tokens = True, padding=False):\n    with torch.no_grad():\n        device = next(llm_model.parameters()).device\n        tokens = llm_tokenizer(\n            prompt, return_tensors=\"pt\",\n            max_length=max_length, \n            truncation=max_length is not None,\n            truncation_strategy = 'longest_first', \n            abs=add_special_tokens, \n            padding=padding\n        )\n        tokens = {_: tokens[_].to(device) for _ in tokens}\n        logits = llm_model(**tokens).logits\n        return compute_entropy(logits=logits, **tokens)\n\n\nclass Batch:\n    def __init__(self, iterable, size=1):\n        self.iterable = iterable\n        self.size = size\n        self.len = len(range(0, len(self.iterable), self.size))\n        \n    def __iter__(self):\n        l = len(self.iterable)\n        n = self.size\n        for ndx in range(0, l, n):\n            yield self.iterable[ndx:min(ndx + n, l)]\n    \n    def __len__(self):\n        return self.len","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:26:13.482274Z","iopub.status.idle":"2024-12-24T08:26:13.482567Z","shell.execute_reply.started":"2024-12-24T08:26:13.482428Z","shell.execute_reply":"2024-12-24T08:26:13.482443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.svm import OneClassSVM\nfrom sklearn.metrics import roc_auc_score\n\nfeats_list = ['Dmed_phi2', 'Lmed_phi2', 'Dp05_phi2', 'Lstd_phi2', 'meanchr_phi2',]\n# classifier = OneClassSVM(verbose=1,  kernel='rbf', gamma='auto',nu=0.05);\nclassifier = OneClassSVM(verbose=1,  kernel='rbf', gamma=0.1,nu=0.01);\n\nlist_op = {\n    'len':  lambda a, axis: np.sum(np.isfinite(a),axis),\n    'med': np.nanmedian,\n    'max': np.nanmax,\n    'mean': np.nanmean,\n    'std': np.nanstd,\n    'p05' : lambda a, axis: np.nanpercentile(a, 5,axis=axis),\n    'p80' : lambda a, axis: np.nanpercentile(a,80,axis=axis),\n    'p90' : lambda a, axis: np.nanpercentile(a,90,axis=axis),\n    'p95' : lambda a, axis: np.nanpercentile(a,95,axis=axis),\n    'p98' : lambda a, axis: np.nanpercentile(a,98,axis=axis),\n    #'lse': logsumexp,\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:26:13.483688Z","iopub.status.idle":"2024-12-24T08:26:13.483998Z","shell.execute_reply.started":"2024-12-24T08:26:13.483821Z","shell.execute_reply":"2024-12-24T08:26:13.483853Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"batch_size = 3\nprint(batch_size)\n#for _ in dict_llm:\n#    print(_, flush=True)\n#    texts = [' '.join(['hello',]*dict_llm[_][2]) for i in range(batch_size)]\n#    vet = generate_logprob(llm_model[_], llm_tokenizer[_], texts, max_length=dict_llm[_][2], padding=True).cpu().numpy()\n#print('done', flush=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:26:13.484770Z","iopub.status.idle":"2024-12-24T08:26:13.485099Z","shell.execute_reply.started":"2024-12-24T08:26:13.484957Z","shell.execute_reply":"2024-12-24T08:26:13.484972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def feature_extraction(tab):\n    for index in tqdm.tqdm(tab.index):\n        text = tab.loc[index,'text']    \n        tab.loc[index,'len_chr'] = len(text)\n    for _ in dict_llm:\n        print(_, flush=True)\n        for index_list in tqdm.tqdm(Batch(tab.index, batch_size)):\n            texts = [tab.loc[index,'text'] for index in index_list]\n            vetD, vetL = generate_logprob(llm_model[_], llm_tokenizer[_], texts, max_length=dict_llm[_][2], padding=True)\n            vetD = vetD.cpu().numpy()\n            vetL = vetL.cpu().numpy()\n            \n            tab.loc[index_list,'meanchr_'+_] = tab.loc[index_list,'len_chr'].values / np.sum(np.isfinite(vetL),-1)\n            \n            for op in list_op:\n                keyD = 'D'+op+'_'+_\n                if keyD in feats_list:\n                    op_vet = list_op[op](vetD, axis=-1)\n                    for index, value in zip(index_list, op_vet):\n                        tab.loc[index, keyD] = value\n                        \n                keyL = 'L'+op+'_'+_\n                if keyL in feats_list:\n                    op_vet = list_op[op](vetL, axis=-1)\n                    for index, value in zip(index_list, op_vet):\n                        tab.loc[index, keyL] = value\n    return tab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:26:13.487437Z","iopub.status.idle":"2024-12-24T08:26:13.487747Z","shell.execute_reply.started":"2024-12-24T08:26:13.487606Z","shell.execute_reply":"2024-12-24T08:26:13.487621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if True:\n    tab_train = feature_extraction(tab_train)\n    print(tab_train.columns)\n    print('done training feature extraction', flush=True)\n\n    train_feats = tab_train[tab_train['generated']==0][feats_list].values\n    z_mean = np.mean(train_feats, 0, keepdims=True)\n    z_std  = np.maximum(np.std(train_feats, 0, keepdims=True), 1e-4)\n\n    classifier.fit((train_feats - z_mean)/z_std)\n    \n    print('done training', flush=True)\n    \nelse:\n    pass\n\nprint(z_mean, z_std)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:26:13.489025Z","iopub.status.idle":"2024-12-24T08:26:13.489325Z","shell.execute_reply.started":"2024-12-24T08:26:13.489185Z","shell.execute_reply":"2024-12-24T08:26:13.489200Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tab_test = pd.read_csv(f'{path_input}/llm-detect-ai-generated-text/test_essays.csv')\ntab_test = feature_extraction(tab_test)\nprint('done test feature extraction', flush=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:26:13.490349Z","iopub.status.idle":"2024-12-24T08:26:13.490616Z","shell.execute_reply.started":"2024-12-24T08:26:13.490484Z","shell.execute_reply":"2024-12-24T08:26:13.490497Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_feats = tab_test[feats_list].values\ntab_test['generated'] = -1.0*classifier.decision_function((test_feats - z_mean)/z_std)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:26:13.491732Z","iopub.status.idle":"2024-12-24T08:26:13.492047Z","shell.execute_reply.started":"2024-12-24T08:26:13.491905Z","shell.execute_reply":"2024-12-24T08:26:13.491920Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission = tab_test[['id','generated']]\n\n# Save the DataFrame to a CSV file\nsubmission.to_csv('submission.csv', index=False)\npd.read_csv(\"/kaggle/working/submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-24T08:26:13.492880Z","iopub.status.idle":"2024-12-24T08:26:13.493178Z","shell.execute_reply.started":"2024-12-24T08:26:13.493038Z","shell.execute_reply":"2024-12-24T08:26:13.493052Z"}},"outputs":[],"execution_count":null}]}