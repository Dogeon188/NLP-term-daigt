{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b19ff94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T05:01:34.697179Z",
     "iopub.status.busy": "2024-12-16T05:01:34.696794Z",
     "iopub.status.idle": "2024-12-16T05:01:40.101525Z",
     "shell.execute_reply": "2024-12-16T05:01:40.100510Z"
    },
    "papermill": {
     "duration": 5.412561,
     "end_time": "2024-12-16T05:01:40.104544",
     "exception": false,
     "start_time": "2024-12-16T05:01:34.691983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers as T\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fddba469",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-16T05:01:40.112303Z",
     "iopub.status.busy": "2024-12-16T05:01:40.111685Z",
     "iopub.status.idle": "2024-12-16T05:01:40.118913Z",
     "shell.execute_reply": "2024-12-16T05:01:40.117648Z"
    },
    "papermill": {
     "duration": 0.013278,
     "end_time": "2024-12-16T05:01:40.121081",
     "exception": false,
     "start_time": "2024-12-16T05:01:40.107803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOST: Batch, IS_RERUN: None\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "HOST: Literal['Localhost', 'Interactive', 'Batch'] = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\n",
    "IS_RERUN: bool = os.getenv('KAGGLE_IS_COMPETITION_RERUN')\n",
    "\n",
    "print(f'HOST: {HOST}, IS_RERUN: {IS_RERUN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d48c73ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T05:01:40.128285Z",
     "iopub.status.busy": "2024-12-16T05:01:40.127931Z",
     "iopub.status.idle": "2024-12-16T05:01:40.133095Z",
     "shell.execute_reply": "2024-12-16T05:01:40.131951Z"
    },
    "papermill": {
     "duration": 0.011393,
     "end_time": "2024-12-16T05:01:40.135439",
     "exception": false,
     "start_time": "2024-12-16T05:01:40.124046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    (\"cuda:3\" if torch.cuda.is_available()\n",
    "     else \"mps\" if torch.backends.mps.is_available()\n",
    "     else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c41f1d97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T05:01:40.143121Z",
     "iopub.status.busy": "2024-12-16T05:01:40.142727Z",
     "iopub.status.idle": "2024-12-16T05:01:40.148877Z",
     "shell.execute_reply": "2024-12-16T05:01:40.147804Z"
    },
    "papermill": {
     "duration": 0.012389,
     "end_time": "2024-12-16T05:01:40.150968",
     "exception": false,
     "start_time": "2024-12-16T05:01:40.138579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_kaggle_csv(dataset: str, name: str, is_comp: bool = False) -> pd.DataFrame:\n",
    "    assert name.endswith('.csv')\n",
    "    if IS_RERUN:\n",
    "        return pd.read_csv(f'/kaggle/input/{dataset}/{name}')\n",
    "    if is_comp:\n",
    "        path = kagglehub.competition_download(dataset)\n",
    "    else:\n",
    "        path = kagglehub.dataset_download(dataset)\n",
    "    return pd.read_csv(Path(path) / name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19da7094",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T05:01:40.158593Z",
     "iopub.status.busy": "2024-12-16T05:01:40.158197Z",
     "iopub.status.idle": "2024-12-16T05:01:45.770808Z",
     "shell.execute_reply": "2024-12-16T05:01:45.769559Z"
    },
    "papermill": {
     "duration": 5.61972,
     "end_time": "2024-12-16T05:01:45.773698",
     "exception": false,
     "start_time": "2024-12-16T05:01:40.153978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if IS_RERUN:\n",
    "    df_train = get_kaggle_csv('daigt-datamix', 'train_essays.csv')\n",
    "    df_test = get_kaggle_csv('llm-detect-ai-generated-text', 'test_essays.csv', is_comp=True)\n",
    "else:\n",
    "    df_train = get_kaggle_csv('dogeon188/daigt-datamix', 'train_essays.csv')\n",
    "    # split df_train into train and test\n",
    "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "    df_test = df_train.iloc[-1000:]\n",
    "    df_train = df_train.iloc[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a3771ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T05:01:45.782271Z",
     "iopub.status.busy": "2024-12-16T05:01:45.781849Z",
     "iopub.status.idle": "2024-12-16T05:02:05.545527Z",
     "shell.execute_reply": "2024-12-16T05:02:05.544460Z"
    },
    "papermill": {
     "duration": 19.77149,
     "end_time": "2024-12-16T05:02:05.548562",
     "exception": false,
     "start_time": "2024-12-16T05:01:45.777072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 647.33it/s]\n",
      "100%|██████████| 10000/10000 [00:16<00:00, 593.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "from tokenizers import Tokenizer, models, normalizers, pre_tokenizers, trainers\n",
    "\n",
    "VOCAB_SIZE = 30000\n",
    "LOWERCASE = False\n",
    "\n",
    "raw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "raw_tokenizer.normalizer = normalizers.Sequence(\n",
    "    [normalizers.NFC()] + [normalizers.Lowercase()] if LOWERCASE else [])\n",
    "raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\n",
    "\n",
    "ds_test = Dataset.from_pandas(df_test[['text']])\n",
    "# ds_train = Dataset.from_pandas(df_train[['text']])\n",
    "\n",
    "\n",
    "def train_corp_iter():\n",
    "    for i in range(0, len(ds_test), 1000):\n",
    "        yield ds_test[i: i + 1000][\"text\"]\n",
    "    # for i in range(0, len(ds_train), 1000):\n",
    "    #     yield ds_train[i: i + 1000][\"text\"]\n",
    "\n",
    "\n",
    "raw_tokenizer.train_from_iterator(\n",
    "    train_corp_iter(),\n",
    "    trainer=trainer,\n",
    "    # length=len(ds_test) + len(ds_train)\n",
    ")\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=raw_tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")\n",
    "\n",
    "tokenized_texts_test = [tokenizer.tokenize(text)\n",
    "                        for text in tqdm(df_test['text'])]\n",
    "tokenized_texts_train = [tokenizer.tokenize(text)\n",
    "                         for text in tqdm(df_train['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce54b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T05:02:05.578801Z",
     "iopub.status.busy": "2024-12-16T05:02:05.578377Z",
     "iopub.status.idle": "2024-12-16T05:02:31.312926Z",
     "shell.execute_reply": "2024-12-16T05:02:31.311573Z"
    },
    "papermill": {
     "duration": 25.753695,
     "end_time": "2024-12-16T05:02:31.316115",
     "exception": false,
     "start_time": "2024-12-16T05:02:05.562420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 610.39it/s]\n",
      "100%|██████████| 10000/10000 [00:13<00:00, 726.17it/s]\n",
      "100%|██████████| 1000/1000 [00:01<00:00, 721.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def dummy(x): return x\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(3, 5), lowercase=False, sublinear_tf=True, analyzer='word',\n",
    "    tokenizer=dummy, preprocessor=dummy,\n",
    "    token_pattern=None, strip_accents='unicode')\n",
    "\n",
    "vectorizer.fit(tqdm(tokenized_texts_test))\n",
    "\n",
    "# Getting vocab\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(3, 5), lowercase=False, sublinear_tf=True, vocabulary=vocab,\n",
    "    analyzer='word', tokenizer=dummy, preprocessor=dummy,\n",
    "    token_pattern=None, strip_accents='unicode'\n",
    ")\n",
    "\n",
    "tf_train = vectorizer.fit_transform(tqdm(tokenized_texts_train))\n",
    "tf_test = vectorizer.transform(tqdm(tokenized_texts_test))\n",
    "\n",
    "\n",
    "del vocab, vectorizer, tokenized_texts_train, tokenized_texts_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49dd8636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T05:02:31.372779Z",
     "iopub.status.busy": "2024-12-16T05:02:31.371396Z",
     "iopub.status.idle": "2024-12-16T05:02:31.378080Z",
     "shell.execute_reply": "2024-12-16T05:02:31.376646Z"
    },
    "papermill": {
     "duration": 0.033697,
     "end_time": "2024-12-16T05:02:31.380487",
     "exception": false,
     "start_time": "2024-12-16T05:02:31.346790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = df_train['generated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7871112",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T05:02:31.426515Z",
     "iopub.status.busy": "2024-12-16T05:02:31.426066Z",
     "iopub.status.idle": "2024-12-16T05:03:04.419357Z",
     "shell.execute_reply": "2024-12-16T05:03:04.415330Z"
    },
    "papermill": {
     "duration": 33.02021,
     "end_time": "2024-12-16T05:03:04.422586",
     "exception": false,
     "start_time": "2024-12-16T05:02:31.402376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Done!\n",
      "SGD Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:31<00:00, 31.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=0.02)\n",
    "\n",
    "sgd_model = SGDClassifier(max_iter=8000, tol=1e-4, loss=\"modified_huber\")\n",
    "\n",
    "LGB_N_ITER = 100 if IS_RERUN else 1\n",
    "lgb = LGBMClassifier(\n",
    "    n_estimators=LGB_N_ITER,\n",
    "    num_leaves=51,\n",
    "    objective='binary',\n",
    "    metric='roc_auc',\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.7,\n",
    "    colsample_bynode=0.6,\n",
    "    lambda_l1=8,\n",
    "    lambda_l2=5,\n",
    "    num_threads=4,\n",
    "    min_data_in_leaf=10,\n",
    "    max_depth=20,\n",
    "    max_bin=900,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "clf.fit(tf_train, y_train)\n",
    "p1 = clf.predict_proba(tf_test)[:, 1]\n",
    "print(\"NB Done!\")\n",
    "\n",
    "sgd_model.fit(tf_train, y_train)\n",
    "p2 = sgd_model.predict_proba(tf_test)[:, 1]\n",
    "print(\"SGD Done!\")\n",
    "\n",
    "pbar = tqdm(total=LGB_N_ITER)\n",
    "lgb.fit(tf_train, y_train, callbacks=[lambda _: pbar.update(1)])\n",
    "p3 = lgb.predict_proba(tf_test)[:, 1]\n",
    "print(\"LGBM Done!\")\n",
    "pbar.close()\n",
    "\n",
    "final_preds = p1 * 0.1 + p2 * 0.45 + p3 * 0.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d368905",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T05:03:04.472095Z",
     "iopub.status.busy": "2024-12-16T05:03:04.470996Z",
     "iopub.status.idle": "2024-12-16T05:03:04.482059Z",
     "shell.execute_reply": "2024-12-16T05:03:04.480888Z"
    },
    "papermill": {
     "duration": 0.037273,
     "end_time": "2024-12-16T05:03:04.484243",
     "exception": false,
     "start_time": "2024-12-16T05:03:04.446970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8984\n"
     ]
    }
   ],
   "source": [
    "if not IS_RERUN:\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    auc_score = roc_auc_score(df_test['generated'], final_preds)\n",
    "    \n",
    "    print(f\"ROC AUC: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf6d6492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-16T05:03:04.529225Z",
     "iopub.status.busy": "2024-12-16T05:03:04.528839Z",
     "iopub.status.idle": "2024-12-16T05:03:04.542789Z",
     "shell.execute_reply": "2024-12-16T05:03:04.541578Z"
    },
    "papermill": {
     "duration": 0.0397,
     "end_time": "2024-12-16T05:03:04.545441",
     "exception": false,
     "start_time": "2024-12-16T05:03:04.505741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test['generated'] = final_preds\n",
    "submission = df_test[['id' if IS_RERUN else 'prompt_id', 'generated']]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7516023,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 4309752,
     "sourceId": 7409832,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6308778,
     "sourceId": 10208045,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 94.424971,
   "end_time": "2024-12-16T05:03:06.193365",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-16T05:01:31.768394",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
