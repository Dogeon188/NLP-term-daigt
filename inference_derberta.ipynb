{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>LLM - Detect AI Generated Text</center>\n",
    "\n",
    "This competition challenges participants to develop a machine learning model that can accurately detect **whether an essay was written by a student or an LLM**. The competition dataset comprises a mix of student-written essays and essays generated by a variety of LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Members: 毛柏毅, 朱誼學, 許木羽, 張立誠"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:03:10.568300Z",
     "iopub.status.busy": "2024-12-19T13:03:10.567969Z",
     "iopub.status.idle": "2024-12-19T13:03:10.572943Z",
     "shell.execute_reply": "2024-12-19T13:03:10.572009Z",
     "shell.execute_reply.started": "2024-12-19T13:03:10.568272Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import transformers as T\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:03:10.574529Z",
     "iopub.status.busy": "2024-12-19T13:03:10.574229Z",
     "iopub.status.idle": "2024-12-19T13:03:10.592251Z",
     "shell.execute_reply": "2024-12-19T13:03:10.591625Z",
     "shell.execute_reply.started": "2024-12-19T13:03:10.574501Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOST: Interactive, IS_RERUN: None\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "HOST: Literal['Localhost', 'Interactive', 'Batch'] = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\n",
    "IS_RERUN: bool = os.getenv('KAGGLE_IS_COMPETITION_RERUN')\n",
    "\n",
    "print(f'HOST: {HOST}, IS_RERUN: {IS_RERUN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:03:10.594109Z",
     "iopub.status.busy": "2024-12-19T13:03:10.593894Z",
     "iopub.status.idle": "2024-12-19T13:03:10.686399Z",
     "shell.execute_reply": "2024-12-19T13:03:10.685505Z",
     "shell.execute_reply.started": "2024-12-19T13:03:10.594086Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\n",
    "    (\"cuda:0\" if torch.cuda.is_available()\n",
    "     else \"mps\" if torch.backends.mps.is_available()\n",
    "     else \"cpu\"))\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:03:10.687836Z",
     "iopub.status.busy": "2024-12-19T13:03:10.687609Z",
     "iopub.status.idle": "2024-12-19T13:03:10.703559Z",
     "shell.execute_reply": "2024-12-19T13:03:10.702765Z",
     "shell.execute_reply.started": "2024-12-19T13:03:10.687817Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def get_kaggle_csv(dataset: str, name: str, is_comp: bool = False) -> pd.DataFrame:\n",
    "    assert name.endswith('.csv')\n",
    "    if IS_RERUN:\n",
    "        return pd.read_csv(f'/kaggle/input/{dataset}/{name}')\n",
    "    if is_comp:\n",
    "        path = kagglehub.competition_download(dataset)\n",
    "    else:\n",
    "        path = kagglehub.dataset_download(dataset)\n",
    "    return pd.read_csv(Path(path) / name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:03:10.704740Z",
     "iopub.status.busy": "2024-12-19T13:03:10.704420Z",
     "iopub.status.idle": "2024-12-19T13:03:16.924249Z",
     "shell.execute_reply": "2024-12-19T13:03:16.923323Z",
     "shell.execute_reply.started": "2024-12-19T13:03:10.704709Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if IS_RERUN:\n",
    "    df_train = get_kaggle_csv('daigt-datamix', 'train_essays.csv')\n",
    "    df_test = get_kaggle_csv('llm-detect-ai-generated-text', 'test_essays.csv', is_comp=True)\n",
    "else:\n",
    "    df_train = get_kaggle_csv('dogeon188/daigt-datamix', 'train_essays.csv')\n",
    "    # split df_train into train and test\n",
    "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "    df_test = df_train.iloc[-1000:]\n",
    "    df_train = df_train.iloc[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:03:16.925513Z",
     "iopub.status.busy": "2024-12-19T13:03:16.925232Z",
     "iopub.status.idle": "2024-12-19T13:03:18.583562Z",
     "shell.execute_reply": "2024-12-19T13:03:18.582604Z",
     "shell.execute_reply.started": "2024-12-19T13:03:16.925489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tokenizer = T.AutoTokenizer.from_pretrained(\"/kaggle/input/src/pytorch/default/1/src/tokenizer\", use_fast=False)\n",
    "source_classes = {'claude': 0, 'cohere': 1, 'falcon': 2, 'gpt': 3, 'llama': 4, 'mistral': 5, 'palm': 6, 'T5': 7, 'human': 8}\n",
    "# Define the hyperparameters\n",
    "lr = 3e-5\n",
    "test_batch_size = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:03:18.584798Z",
     "iopub.status.busy": "2024-12-19T13:03:18.584479Z",
     "iopub.status.idle": "2024-12-19T13:03:18.593812Z",
     "shell.execute_reply": "2024-12-19T13:03:18.593031Z",
     "shell.execute_reply.started": "2024-12-19T13:03:18.584769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, split=\"train\") -> None:\n",
    "        super().__init__()\n",
    "        assert split in [\"train\", \"validation\", \"test\"]\n",
    "        if split != 'test':\n",
    "            self.data = df[split]\n",
    "        else:\n",
    "            self.data = df\n",
    "    def __getitem__(self, index):\n",
    "        d = self.data.iloc[index]\n",
    "        return d\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    texts = [item['text'] for item in batch]\n",
    "    try:\n",
    "        generated = [item['generated'] for item in batch]\n",
    "    except:\n",
    "        generated = []\n",
    "\n",
    "    encoded_inputs = tokenizer(\n",
    "        texts,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256\n",
    "    )\n",
    "\n",
    "    generated_tensor = torch.tensor(generated)\n",
    "\n",
    "    return {\n",
    "        'input_ids': encoded_inputs['input_ids'],\n",
    "        'token_type_ids': encoded_inputs['token_type_ids'],\n",
    "        'attention_mask': encoded_inputs['attention_mask'],\n",
    "        'generated': generated_tensor\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:03:18.595141Z",
     "iopub.status.busy": "2024-12-19T13:03:18.594813Z",
     "iopub.status.idle": "2024-12-19T13:03:18.613352Z",
     "shell.execute_reply": "2024-12-19T13:03:18.612594Z",
     "shell.execute_reply.started": "2024-12-19T13:03:18.595109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Deberta(torch.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.deberta = T.AutoModel.from_pretrained(\"/kaggle/input/src_for_comp/pytorch/default/1/src_for_comp/deberta\", num_labels=1)\n",
    "        self.deberta.gradient_checkpointing_enable()\n",
    "\n",
    "        self.linear = torch.nn.Sequential(\n",
    "            torch.nn.Linear(768, 384),\n",
    "            torch.nn.Linear(384, 1)\n",
    "        )\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "    def forward(self, **kwargs):\n",
    "        input_ids = kwargs['input_ids']\n",
    "        attention_mask = kwargs['attention_mask']\n",
    "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "        # Mean pooling\n",
    "        # reshape attention_mask, used to filter the valid tokens\n",
    "        mask = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()  # [batch_size, seq_len, hidden_size]\n",
    "        # summation for valid tokens\n",
    "        sum_embeddings = torch.sum(last_hidden_state * mask, dim=1)  # [batch_size, hidden_size]\n",
    "        # num of valid tokens\n",
    "        sum_mask = torch.clamp(mask.sum(dim=1), min=1e-9)\n",
    "        x = sum_embeddings / sum_mask\n",
    "        \n",
    "        x = self.linear(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return {\n",
    "            'generated': x\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:03:18.615281Z",
     "iopub.status.busy": "2024-12-19T13:03:18.615032Z",
     "iopub.status.idle": "2024-12-19T13:03:55.725623Z",
     "shell.execute_reply": "2024-12-19T13:03:55.724872Z",
     "shell.execute_reply.started": "2024-12-19T13:03:18.615263Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test: 100%|██████████| 50/50 [00:21<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "model = Deberta().to(device)\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/src_for_comp/pytorch/default/1/src_for_comp/model\", weights_only=True))\n",
    "\n",
    "ds_test = CustomDataset(df_test.copy(), \"test\")\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=test_batch_size, collate_fn=collate_fn)\n",
    "\n",
    "pbar = tqdm(dl_test)\n",
    "pbar.set_description(f\"Test\")\n",
    "model.eval()\n",
    "\n",
    "final_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "        for batch in pbar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            generated = batch['generated'].to(device)\n",
    "            \n",
    "            pred = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            final_preds.extend(list(map(lambda x: x.item(), pred['generated'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:03:55.726925Z",
     "iopub.status.busy": "2024-12-19T13:03:55.726436Z",
     "iopub.status.idle": "2024-12-19T13:03:56.333943Z",
     "shell.execute_reply": "2024-12-19T13:03:56.333217Z",
     "shell.execute_reply.started": "2024-12-19T13:03:55.726901Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.4949\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "if not IS_RERUN:\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    auc_score = roc_auc_score(df_test['generated'], final_preds)\n",
    "    \n",
    "    print(f\"ROC AUC: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-19T13:03:56.335427Z",
     "iopub.status.busy": "2024-12-19T13:03:56.334852Z",
     "iopub.status.idle": "2024-12-19T13:03:56.354736Z",
     "shell.execute_reply": "2024-12-19T13:03:56.354099Z",
     "shell.execute_reply.started": "2024-12-19T13:03:56.335387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_test['generated'] = final_preds\n",
    "submission = df_test[['id' if IS_RERUN else 'prompt_id', 'generated']]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7516023,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 10499747,
     "datasetId": 6308778,
     "sourceId": 10208045,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 10542543,
     "modelInstanceId": 173773,
     "sourceId": 203684,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
