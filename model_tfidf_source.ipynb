{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>LLM - Detect AI Generated Text</center>\n",
    "\n",
    "This competition challenges participants to develop a machine learning model that can accurately detect **whether an essay was written by a student or an LLM**. The competition dataset comprises a mix of student-written essays and essays generated by a variety of LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Members: 毛柏毅, 朱誼學, 許木羽, 張立誠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install transformers\n",
    "# %pip install peft\n",
    "# %pip install bitsandbytes\n",
    "# %pip install accelerate\n",
    "# %pip install omegaconf\n",
    "# %pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers as T\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import kagglehub\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "HOST: Literal['Localhost', 'Interactive', 'Batch'] = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\n",
    "IS_RERUN: bool = os.getenv('KAGGLE_IS_COMPETITION_RERUN')\n",
    "\n",
    "print(f'HOST: {HOST}, IS_RERUN: {IS_RERUN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    (\"cuda:3\" if torch.cuda.is_available()\n",
    "     else \"mps\" if torch.backends.mps.is_available()\n",
    "     else \"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kaggle_csv(dataset: str, name: str, is_comp: bool = False) -> pd.DataFrame:\n",
    "    assert name.endswith('.csv')\n",
    "    if IS_RERUN:\n",
    "        return pd.read_csv(f'/kaggle/input/{dataset}/{name}')\n",
    "    if is_comp:\n",
    "        path = kagglehub.competition_download(dataset)\n",
    "    else:\n",
    "        path = kagglehub.dataset_download(dataset)\n",
    "    return pd.read_csv(Path(path) / name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IS_RERUN:\n",
    "    df_train = get_kaggle_csv('daigt-datamix', 'train_essays.csv')\n",
    "    df_test = get_kaggle_csv('llm-detect-ai-generated-text', 'test_essays.csv', is_comp=True)\n",
    "else:\n",
    "    df_train = get_kaggle_csv('dogeon188/daigt-datamix', 'train_essays.csv')\n",
    "    # split df_train into train and test\n",
    "    df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "    df_test = df_train.iloc[-1000:]\n",
    "    df_train = df_train.iloc[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 4016.25it/s]\n",
      "100%|██████████| 99836/99836 [01:19<00:00, 1248.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "from tokenizers import Tokenizer, models, normalizers, pre_tokenizers, trainers\n",
    "\n",
    "VOCAB_SIZE = 30000\n",
    "LOWERCASE = True\n",
    "\n",
    "raw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n",
    "raw_tokenizer.normalizer = normalizers.Sequence(\n",
    "    [normalizers.NFC()] + [normalizers.Lowercase()] if LOWERCASE else [])\n",
    "raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\n",
    "\n",
    "ds_test = Dataset.from_pandas(df_test[['text']])\n",
    "# ds_train = Dataset.from_pandas(df_train[['text']])\n",
    "\n",
    "\n",
    "def train_corp_iter():\n",
    "    for i in range(0, len(ds_test), 1000):\n",
    "        yield ds_test[i: i + 1000][\"text\"]\n",
    "    # for i in range(0, len(ds_train), 1000):\n",
    "    #     yield ds_train[i: i + 1000][\"text\"]\n",
    "\n",
    "\n",
    "raw_tokenizer.train_from_iterator(\n",
    "    train_corp_iter(),\n",
    "    trainer=trainer,\n",
    "    # length=len(ds_test) + len(ds_train)\n",
    ")\n",
    "\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=raw_tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")\n",
    "\n",
    "tokenized_texts_test = [tokenizer.tokenize(text)\n",
    "                        for text in tqdm(df_test['text'])]\n",
    "tokenized_texts_train = [tokenizer.tokenize(text)\n",
    "                         for text in tqdm(df_train['text'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1041.63it/s]\n",
      "100%|██████████| 99836/99836 [00:39<00:00, 2514.95it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 11115.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def dummy(x): return x\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(3, 5), lowercase=False, sublinear_tf=True, analyzer='word',\n",
    "    tokenizer=dummy, preprocessor=dummy,\n",
    "    token_pattern=None, strip_accents='unicode')\n",
    "\n",
    "vectorizer.fit(tqdm(tokenized_texts_test))\n",
    "\n",
    "# Getting vocab\n",
    "vocab = vectorizer.vocabulary_\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(3, 5), lowercase=False, sublinear_tf=True, vocabulary=vocab,\n",
    "    analyzer='word', tokenizer=dummy, preprocessor=dummy,\n",
    "    token_pattern=None, strip_accents='unicode'\n",
    ")\n",
    "\n",
    "tf_train = vectorizer.fit_transform(tqdm(tokenized_texts_train))\n",
    "tf_test = vectorizer.transform(tqdm(tokenized_texts_test))\n",
    "\n",
    "del vocab, vectorizer, tokenized_texts_train, tokenized_texts_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['source']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Done!\n",
      "SGD Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [1:04:04<00:00, 153.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/dogeon/Documents/code/py/nlp/final/.venv/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=0.02)\n",
    "\n",
    "sgd_model = SGDClassifier(max_iter=8000, tol=1e-4, loss=\"modified_huber\")\n",
    "\n",
    "LGB_N_ITER = 100 if IS_RERUN else 1\n",
    "lgb = LGBMClassifier(\n",
    "    n_estimators=LGB_N_ITER,\n",
    "    num_leaves=51,\n",
    "    objective='binary',\n",
    "    metric='roc_auc',\n",
    "    learning_rate=0.05,\n",
    "    colsample_bytree=0.7,\n",
    "    colsample_bynode=0.6,\n",
    "    lambda_l1=8,\n",
    "    lambda_l2=5,\n",
    "    num_threads=4,\n",
    "    min_data_in_leaf=10,\n",
    "    max_depth=20,\n",
    "    max_bin=900,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "clf.fit(tf_train, y_train)\n",
    "human_idx = np.where(clf.classes_ == 'human')[0][0]\n",
    "print(\"NB Done!\")\n",
    "\n",
    "sgd_model.fit(tf_train, y_train)\n",
    "human_idx = np.where(sgd_model.classes_ == 'human')[0][0]\n",
    "print(\"SGD Done!\")\n",
    "\n",
    "pbar = tqdm(total=LGB_N_ITER)\n",
    "lgb.fit(tf_train, y_train, callbacks=[lambda x: pbar.update(1)])\n",
    "human_idx = np.where(lgb.classes_ == 'human')[0][0]\n",
    "print(\"LGBM Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not IS_RERUN:\n",
    "    from sklearn.metrics import log_loss, roc_auc_score\n",
    "\n",
    "    # examine the predictions\n",
    "    p1 = clf.predict_proba(tf_test)\n",
    "    p2 = sgd_model.predict_proba(tf_test)\n",
    "    p3 = lgb.predict_proba(tf_test)\n",
    "    final_preds = p1*0.1 + p2*0.45 + p3*0.45\n",
    "    \n",
    "    # calculate the final score\n",
    "    mc_score = log_loss(df_test['source'], final_preds)\n",
    "\n",
    "    p1 = p1[:, np.where(clf.classes_ == 'human')[0][0]]\n",
    "    p2 = p2[:, np.where(sgd_model.classes_ == 'human')[0][0]]\n",
    "    p3 = p3[:, np.where(lgb.classes_ == 'human')[0][0]]\n",
    "    final_preds = 1 - p1*0.1 + p2*0.45 + p3*0.45\n",
    "    auc_score = roc_auc_score(df_test['generated'], final_preds)\n",
    "\n",
    "    print(f\"Multiclass log loss: {mc_score:.4f}\")\n",
    "    print(f\"ROC AUC: {auc_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = clf.predict_proba(tf_test)[:, np.where(clf.classes_ == 'human')[0][0]]\n",
    "p2 = sgd_model.predict_proba(tf_test)[:, np.where(sgd_model.classes_ == 'human')[0][0]]\n",
    "p3 = lgb.predict_proba(tf_test)[:, np.where(lgb.classes_ == 'human')[0][0]]\n",
    "final_preds = p1*0.1 + p2*0.45 + p3*0.45\n",
    "final_preds = 1 - final_preds\n",
    "\n",
    "df_test['generated'] = final_preds\n",
    "submission = df_test[['id' if IS_RERUN else 'prompt_id', 'generated']]\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
