{"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":7516023,"sourceType":"competition"},{"sourceId":7409832,"sourceType":"datasetVersion","datasetId":4309752},{"sourceId":10208045,"sourceType":"datasetVersion","datasetId":6308778}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <center>LLM - Detect AI Generated Text</center>\n\nThis competition challenges participants to develop a machine learning model that can accurately detect **whether an essay was written by a student or an LLM**. The competition dataset comprises a mix of student-written essays and essays generated by a variety of LLMs.","metadata":{}},{"cell_type":"markdown","source":"Team Members: 毛柏毅, 朱誼學, 許木羽, 張立誠","metadata":{}},{"cell_type":"code","source":"# %pip install transformers\n# %pip install peft\n# %pip install bitsandbytes\n# %pip install accelerate\n# %pip install omegaconf\n# %pip install lightgbm","metadata":{},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"## Configuration","metadata":{}},{"cell_type":"code","source":"import transformers as T\nfrom datasets import Dataset\nimport torch\n# from torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport kagglehub\nimport numpy as np\n\nimport os\nimport gc\nfrom pathlib import Path\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom IPython.display import display, HTML","metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from typing import Literal\n\nHOST: Literal['Localhost', 'Interactive', 'Batch'] = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost')\nIS_RERUN: bool = os.getenv('KAGGLE_IS_COMPETITION_RERUN')\n\nprint(f'HOST: {HOST}, IS_RERUN: {IS_RERUN}')","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["HOST: Localhost, IS_RERUN: None\n"]}],"execution_count":3},{"cell_type":"code","source":"device = torch.device(\n    (\"cuda:3\" if torch.cuda.is_available()\n     else \"mps\" if torch.backends.mps.is_available()\n     else \"cpu\"))","metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"def get_kaggle_csv(dataset: str, name: str, is_comp: bool = False) -> pd.DataFrame:\n    assert name.endswith('.csv')\n    if IS_RERUN:\n        return pd.read_csv(f'/kaggle/input/{dataset}/{name}')\n    if is_comp:\n        path = kagglehub.competition_download(dataset)\n    else:\n        path = kagglehub.dataset_download(dataset)\n    return pd.read_csv(Path(path) / name)","metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":"if IS_RERUN:\n    df_train = get_kaggle_csv('daigt-datamix', 'train_essays.csv')\n    df_test = get_kaggle_csv('llm-detect-ai-generated-text', 'test_essays.csv', is_comp=True)\nelse:\n    df_train = get_kaggle_csv('dogeon188/daigt-datamix', 'train_essays.csv')\n    # split df_train into train and test\n    df_train = df_train.sample(frac=1).reset_index(drop=True)\n    df_test = df_train.iloc[-1000:]\n    df_train = df_train.iloc[:10000]\ndf_train = df_train[df_train['source'] != 'unknown']","metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"markdown","source":"### Preprocess Data","metadata":{}},{"cell_type":"code","source":"from transformers import PreTrainedTokenizerFast\nfrom tokenizers import Tokenizer, models, normalizers, pre_tokenizers, trainers\n\nVOCAB_SIZE = 30000\nLOWERCASE = False\n\nraw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\nraw_tokenizer.normalizer = normalizers.Sequence(\n    [normalizers.NFC()] + [normalizers.Lowercase()] if LOWERCASE else [])\nraw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\nspecial_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\ntrainer = trainers.BpeTrainer(\n    vocab_size=VOCAB_SIZE, special_tokens=special_tokens)\n\nds_test = Dataset.from_pandas(df_test[['text']])\nds_train = Dataset.from_pandas(df_train[['text']])\n\n\ndef train_corp_iter():\n    for i in range(0, len(ds_test), 1000):\n        yield ds_test[i: i + 1000][\"text\"]\n    # for i in range(0, len(ds_train), 1000):\n    #     yield ds_train[i: i + 1000][\"text\"]\n\n\nraw_tokenizer.train_from_iterator(\n    train_corp_iter(),\n    trainer=trainer,\n    # length=len(ds_test) + len(ds_train)\n)\n\ntokenizer = PreTrainedTokenizerFast(\n    tokenizer_object=raw_tokenizer,\n    unk_token=\"[UNK]\",\n    pad_token=\"[PAD]\",\n    cls_token=\"[CLS]\",\n    sep_token=\"[SEP]\",\n    mask_token=\"[MASK]\",\n)\n\ntokenized_texts_test = [tokenizer.tokenize(text)\n                        for text in tqdm(df_test['text'])]\ntokenized_texts_train = [tokenizer.tokenize(text)\n                         for text in tqdm(df_train['text'])]","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","\n"]},{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","100%|██████████| 1000/1000 [00:00<00:00, 1285.74it/s]\n","100%|██████████| 10000/10000 [00:07<00:00, 1296.34it/s]\n"]}],"execution_count":7},{"cell_type":"markdown","source":"### TFIDF","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n\ndef dummy(x): return x\n\n\nvectorizer = TfidfVectorizer(\n    ngram_range=(3, 5), lowercase=False, sublinear_tf=True, analyzer='word',\n    tokenizer=dummy, preprocessor=dummy,\n    token_pattern=None, strip_accents='unicode')\n\nvectorizer.fit(tqdm(tokenized_texts_test))\n\n# Getting vocab\nvocab = vectorizer.vocabulary_\n\nvectorizer = TfidfVectorizer(\n    ngram_range=(3, 5), lowercase=False, sublinear_tf=True, vocabulary=vocab,\n    analyzer='word', tokenizer=dummy, preprocessor=dummy,\n    token_pattern=None, strip_accents='unicode'\n)\n\ntf_train = vectorizer.fit_transform(tqdm(tokenized_texts_train))\ntf_test = vectorizer.transform(tqdm(tokenized_texts_test))\n\ndel vocab, vectorizer, tokenized_texts_train, tokenized_texts_test\ngc.collect()","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1000/1000 [00:00<00:00, 1549.96it/s]\n","100%|██████████| 10000/10000 [00:06<00:00, 1578.22it/s]\n","100%|██████████| 1000/1000 [00:00<00:00, 1730.96it/s]\n"]},{"data":{"text/plain":["0"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"execution_count":8},{"cell_type":"code","source":"y_train = df_train['source']\n","metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":"CLASS_HUMAN_FACTOR = 3000","metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":"from lightgbm import LGBMClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB\n\nclf = MultinomialNB(alpha=0.02)\n\nclass_weight = df_train['source'].value_counts(normalize=True).to_dict()\nclass_weight['human'] *= CLASS_HUMAN_FACTOR\nclass_weight = {k: v / sum(class_weight.values()) for k, v in class_weight.items()}\n\nsgd_model = SGDClassifier(\n    max_iter=8000,\n    tol=1e-4,\n    loss=\"modified_huber\",\n    class_weight=class_weight,\n)\n\nLGB_N_ITER = 100 if IS_RERUN else 1\nlgb = LGBMClassifier(\n    n_estimators=LGB_N_ITER,\n    num_leaves=51,\n    objective='multiclass',\n    metric='multi_logloss',\n    learning_rate=0.05,\n    colsample_bytree=0.7,\n    colsample_bynode=0.6,\n    lambda_l1=8,\n    lambda_l2=5,\n    num_threads=4,\n    min_data_in_leaf=10,\n    max_depth=20,\n    max_bin=900,\n    verbose=-1,\n    class_weight=class_weight,\n)\n\nclf.fit(tf_train, y_train)\nhuman_idx = np.where(clf.classes_ == 'human')[0][0]\nprint(\"NB Done!\")\n\nsgd_model.fit(tf_train, y_train)\nhuman_idx = np.where(sgd_model.classes_ == 'human')[0][0]\nprint(\"SGD Done!\")\n\npbar = tqdm(total=LGB_N_ITER)\nlgb.fit(tf_train, y_train, callbacks=[lambda x: pbar.update(1)])\nhuman_idx = np.where(lgb.classes_ == 'human')[0][0]\nprint(\"LGBM Done!\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NB Done!\n","SGD Done!\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1/1 [00:17<00:00, 17.84s/it]\n","100%|██████████| 1/1 [00:07<00:00,  7.39s/it]"]},{"name":"stdout","output_type":"stream","text":["LGBM Done!\n"]}],"execution_count":43},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"if not IS_RERUN:\n    from sklearn.metrics import log_loss, roc_auc_score\n\n    # examine the predictions\n    p1 = clf.predict_proba(tf_test)\n    p2 = sgd_model.predict_proba(tf_test)\n    p3 = lgb.predict_proba(tf_test)\n    final_preds = p1*0.1 + p2*0.45 + p3*0.45\n    \n    # calculate the final score\n    mc_score = log_loss(df_test['source'], final_preds)\n\n    p1 = p1[:, np.where(clf.classes_ == 'human')[0][0]]\n    p2 = p2[:, np.where(sgd_model.classes_ == 'human')[0][0]]\n    p3 = p3[:, np.where(lgb.classes_ == 'human')[0][0]]\n    final_preds = p1*0.1 + p2*0.45 + p3*0.45\n    final_preds = 1 - final_preds\n    auc_score = roc_auc_score(df_test['generated'], final_preds)\n\n    print(f\"Multiclass log loss: {mc_score:.4f}\")\n    print(f\"ROC AUC: {auc_score:.4f}\")","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Multiclass log loss: 1.1625\n","ROC AUC: 0.8305\n"]}],"execution_count":44},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"p1 = clf.predict_proba(tf_test)[:, np.where(clf.classes_ == 'human')[0][0]]\np2 = sgd_model.predict_proba(tf_test)[:, np.where(\n    sgd_model.classes_ == 'human')[0][0]]\np3 = lgb.predict_proba(tf_test)[:, np.where(lgb.classes_ == 'human')[0][0]]\nfinal_preds = p1*0.1 + p2*0.45 + p3*0.45\nfinal_preds = 1 - final_preds\n\nsubmission = df_test.copy()\nsubmission['generated'] = final_preds\nsubmission = submission[['id' if IS_RERUN else 'prompt_id', 'generated']]\nsubmission.to_csv('submission.csv', index=False)","metadata":{},"outputs":[],"execution_count":45}]}